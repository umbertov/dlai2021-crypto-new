method: bayes
metric:
  name: val/f1
  goal: maximize


program: src/run.py

command:
  - ${env}
  - ${interpreter}
  - ${program}
  - ${args_no_hyphens}

parameters:
  experiment:
    values:
      - lstm_small
      - lstm_large
      - tcn_small_shallow
      - tcn_small_deep
      - tcn_wide_shallow
      - tcn_wide_deep

  train.early_stopping.patience:
    distribution: constant
    value: 15

  train.pl_trainer.max_epochs:
    distribution: constant
    value: 80

  train.pl_trainer.gradient_clip_val:
    distribution: categorical
    values: [ 1.0, 0.0, 0.5 ]

  data.datamodule.batch_size.train:
    distribution: categorical
    values: [64,128,256]

  optim.optimizer.lr:
    distribution: categorical
    values: [0.01, 0.001, 0.0001]


  model.classification_loss_fn.minimum_weight:
    distribution: categorical
    values: [0.1, 0.05, 0.001]

  model.classification_loss_fn.decay:
    distribution: categorical
    values: [ 0.9, 0.8 ]

  model.classification_loss_fn.label_smoothing:
    distribution: categorical
    values: [0.0, 0.05]

  dataset_conf:
    distribution: constant
    value: trend_fixclf_multivar

  dataset_conf.dataset_reader.trend_period:
    distribution: categorical
    values: [5,10,20]

  dataset_conf.dataset_reader.alpha:
    distribution: categorical
    values: [0.01, 0.008, 0.015, 0.005, 0.02]

  dataset_conf.zscore_scale_windows:
    distribution: categorical
    values: [False, True]

  dataset_conf.window_length:
    distribution: constant
    value: 128

  model.dropout:
    distribution: categorical
    values: [0.1,0.2]
